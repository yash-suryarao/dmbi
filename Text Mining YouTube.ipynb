{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f77ccc-2b7a-448c-b582-03329d3bd5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEXT MINING on YouTube Comments\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Uncomment these lines if running for the first time\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# Load dataset\n",
    "file_path = 'path_to_youtube_dataset.csv'  # Replace with your file path\n",
    "youtube_data = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure the dataset contains a 'Comments' column\n",
    "if 'Comments' in youtube_data.columns:\n",
    "    comments = youtube_data['Comments'].dropna()\n",
    "else:\n",
    "    raise ValueError(\"The dataset does not contain a 'Comments' column.\")\n",
    "\n",
    "# Text preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Remove URLs, mentions, hashtags, special characters, and numbers\n",
    "    text = re.sub(r'http\\S+|@\\S+|#\\S+|[^a-zA-Z\\s]', '', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "youtube_data['Cleaned Comments'] = comments.apply(preprocess_text)\n",
    "\n",
    "# Combine all comments into one string for word frequency analysis\n",
    "all_comments = ' '.join(youtube_data['Cleaned Comments'])\n",
    "\n",
    "# Remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_words = [word for word in all_comments.split() if word not in stop_words]\n",
    "\n",
    "# Most common words\n",
    "word_counts = Counter(filtered_words)\n",
    "common_words = word_counts.most_common(10)\n",
    "\n",
    "# Sentiment analysis\n",
    "from textblob import TextBlob\n",
    "\n",
    "youtube_data['Sentiment'] = youtube_data['Cleaned Comments'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "\n",
    "# Outputs\n",
    "# 1. Cleaned comments\n",
    "cleaned_comments = youtube_data['Cleaned Comments'].tolist()\n",
    "\n",
    "# 2. Most common words\n",
    "print(\"Most Common Words and Their Frequencies:\")\n",
    "for word, freq in common_words:\n",
    "    print(f\"{word}: {freq}\")\n",
    "\n",
    "# 3. Sentiments\n",
    "print(\"\\nSentiments for Comments:\")\n",
    "for i, sentiment in enumerate(youtube_data['Sentiment']):\n",
    "    print(f\"Comment {i + 1}: Sentiment Polarity = {sentiment}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3f3378f-2590-4f2d-9b28-3e1af75435fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Video Publish Time  Publish Hour Publish Month  Publish Year Day of Week\n",
      "0    2016-06-02 00:00:00             0          June          2016    Thursday\n",
      "1    2016-06-10 00:00:00             0          June          2016      Friday\n",
      "2    2016-06-14 00:00:00             0          June          2016     Tuesday\n",
      "3    2016-06-29 00:00:00             0          June          2016   Wednesday\n",
      "4    2016-07-01 00:00:00             0          July          2016      Friday\n",
      "..                   ...           ...           ...           ...         ...\n",
      "359  2024-08-25 00:00:00             0        August          2024      Sunday\n",
      "360  2024-09-01 00:00:00             0     September          2024      Sunday\n",
      "361  2024-09-16 00:00:00             0     September          2024      Monday\n",
      "362  2024-09-25 00:00:00             0     September          2024   Wednesday\n",
      "363  2024-10-18 00:00:00             0       October          2024      Friday\n",
      "\n",
      "[364 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Text Mining on Video Publish Time and Day Of Week\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "file_path = 'youtube_channel_real_performance_analytics.csv'  # Replace with your file path\n",
    "youtube_data = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure necessary columns are present\n",
    "if 'Video Publish Time' not in youtube_data.columns or 'Day of Week' not in youtube_data.columns:\n",
    "    raise ValueError(\"The dataset does not contain required columns: 'Video Publish Time' or 'Day of Week'.\")\n",
    "\n",
    "# Extract components from 'Video Publish Time'\n",
    "youtube_data['Publish Hour'] = pd.to_datetime(youtube_data['Video Publish Time']).dt.hour\n",
    "youtube_data['Publish Month'] = pd.to_datetime(youtube_data['Video Publish Time']).dt.month_name()\n",
    "youtube_data['Publish Year'] = pd.to_datetime(youtube_data['Video Publish Time']).dt.year\n",
    "\n",
    "# Output extracted data\n",
    "video_publish_time_output = youtube_data[['Video Publish Time', 'Publish Hour', 'Publish Month', 'Publish Year', 'Day of Week']]\n",
    "\n",
    "print(video_publish_time_output)\n",
    "# Save to a CSV file\n",
    "# output_file_path = 'youtube_video_publish_time_analysis.csv'\n",
    "# video_publish_time_output.to_csv(output_file_path, index=False)\n",
    "\n",
    "# print(f\"Results saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c1578e-86db-4208-a4ef-c0ba0be12690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Mining on Video Publish Time and Day Of Week Visualization\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import seaborn as sns\n",
    "\n",
    "# Load dataset\n",
    "file_path = 'path_to_youtube_dataset.csv'  # Replace with your file path\n",
    "youtube_data = pd.read_csv(file_path)\n",
    "\n",
    "# Extract components from 'Video Publish Time'\n",
    "youtube_data['Publish Hour'] = pd.to_datetime(youtube_data['Video Publish Time']).dt.hour\n",
    "youtube_data['Publish Month'] = pd.to_datetime(youtube_data['Video Publish Time']).dt.month_name()\n",
    "youtube_data['Publish Year'] = pd.to_datetime(youtube_data['Video Publish Time']).dt.year\n",
    "\n",
    "# Generate word clouds\n",
    "def generate_wordcloud(text, title):\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "# Word Cloud for 'Day of Week'\n",
    "text_day_of_week = ' '.join(youtube_data['Day of Week'])\n",
    "generate_wordcloud(text_day_of_week, \"Word Cloud: Days of the Week\")\n",
    "\n",
    "# Word Cloud for 'Publish Month'\n",
    "text_publish_month = ' '.join(youtube_data['Publish Month'])\n",
    "generate_wordcloud(text_publish_month, \"Word Cloud: Publish Months\")\n",
    "\n",
    "# Frequency Analysis: Publish Hour\n",
    "publish_hour_counts = youtube_data['Publish Hour'].value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=publish_hour_counts.index, y=publish_hour_counts.values, palette='coolwarm')\n",
    "plt.title('Frequency of Videos Published by Hour', fontsize=16)\n",
    "plt.xlabel('Publish Hour', fontsize=12)\n",
    "plt.ylabel('Number of Videos', fontsize=12)\n",
    "plt.xticks(range(0, 24))\n",
    "plt.show()\n",
    "\n",
    "# Frequency Analysis: Days of the Week\n",
    "day_counts = youtube_data['Day of Week'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=day_counts.index, y=day_counts.values, palette='viridis')\n",
    "plt.title('Frequency of Videos Published by Day of the Week', fontsize=16)\n",
    "plt.xlabel('Day of the Week', fontsize=12)\n",
    "plt.ylabel('Number of Videos', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
